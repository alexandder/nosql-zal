= Technologie nosql - zaliczenie
Aleksander Bolt <aleksanderbolt@yahoo.com>
:icons: font

W projekcie użyłem następujący sprzęt i technologie:

[format="csv"]
|===
Procesor, Intel(R) Core(TM) i5-2430M CPU @ 2.40GHz
Pamięc RAM, 8GB
Dysk, SSD
System operacyjny, Linux 3.13.0-24-generic Mint 17 Qiana
MongoDB, 3.0.7
PostgreSQL, 9.3.5
Python, 2.7.7
PyMongo, 3.1.1
Psycopg2, 2.6.1
|===

Poddałem analizie zbiór https://dl.dropboxusercontent.com/u/15056258/mongodb/reddit.zip[subreditów]. Spakowany w formacie zip ma on 209,6 MB, zaś rozpakowany 1,2 GB.

== Przetwarzane wstępne

W celu zaimportowania danych do bazy PostgreSQL wygodniej jest operować plikiem w formacie json. Przekształcamy pobrany plik subreddit.bson poleceniem:

[source]
bsondump subreddit.bson > subreddit.json

Ponieważ w opisie subredditów znajdują się często słowa z pojedynczym apostrofem (na przykład don't), zastępujemy znak ' znakiem spacji. W przeciwnym wypadku otrzymalibyśmy błąd przy próbie wstawienia danych. Można to zrobić np. tak

[source]
sed "s/'/ /g" subreddit.json > subreddits.json

== Import danych

Importujemy do MongoDB pobrany plik subreddit.bson, poleceniem:

[source]
time mongorestore -d nosql -c subreddit subreddit.bson

image::https://github.com/alexandder/nosql-zal/blob/master/images/mongoStart.jpg[]

image::https://github.com/alexandder/nosql-zal/blob/master/images/mongoEnd.jpg[]

Czas importu wynosi 3 minuty i 13 sekund.

W celu zaimportowania danych do bazy PostgreSQL, tworzymy najpierw tabelę:

[source]
CREATE TABLE subreddits(
	id serial primary key,
	data json
);

Do importu wykorzystamy biblotekę psycopg2 oraz https://github.com/alexandder/nosql-zal/blob/master/insert.py[skrypt]. 
W jego wyniku otrzymamy

image::https://github.com/alexandder/nosql-zal/blob/master/images/postgresInsert.jpg[]

Czas importu wynosi 6 minut i 17 sekund

== Zliczanie rekordów

W obu bazach zliczamy rekordy:

image::https://github.com/alexandder/nosql-zal/blob/master/images/mongoCount.jpg[]

image::https://github.com/alexandder/nosql-zal/blob/master/images/postgresCount.jpg[]


Zatem w obu przypadkach zaimportowaliśmy 904490 rekordów.

== Agregacje
Każdy subreddit może mieć określony jeden obowiązujący język (albo nie mieć). Obliczymy jakie języki występują najczęściej a jakie najrzadziej. W tym celu wykorzystamy zapytanie:
[source]
SELECT data->>'lang' as Language, COUNT(*) as Quantity FROM subreddits GROUP BY data->>'lang' ORDER BY Quantity DESC LIMIT 10;

W wyniku niego otrzymujemy listę 10 najczęściej występujących języków:
|===
|Język |Liczba wystąpień 

|en
|600881

|nieokreślony
|277575

|es
|4172

|de
|3299

|fr
|2080

|sv
|2073

|nl
|1934

|pt
|1775

|no
|956

|tr
|883
|===

Korzystając z biblioteki PyMongo, obliczmy jakie języki występują najrzadziej:
[source]
db.subreddits.aggregate([{"$group" : {"_id" : "$lang", "count" : {"$sum" : 1}}},
                                      {"$sort" : {"count" : 1}},
                                      {"$limit" : 10}])
|===
|Język |Liczba wystąpień 

|leet
|1

|gd
|6

|eu
|6

|nn
|12

|bs
|18

|hy
|24

|be
|30

|ta
|32

|lv
|35

|la
|49
|===
